{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup,TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1660 SUPER\n",
      "device set to => cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():     \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "print( 'device set to =>', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_csv='./test.csv'\n",
    "    test_csv='./train.csv'\n",
    "    sub_csv='./sample_submission.csv'\n",
    "\n",
    "    model='anferico/bert-for-patents'    \n",
    "    max_len=32\n",
    "    num_epoch=2\n",
    "    batch_size=64\n",
    "    epochs=3\n",
    "    lr=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "seed_everything(seed=42)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( Config.train_csv )\n",
    "test_df = pd.read_csv( Config.test_csv )\n",
    "sub_df = pd.read_csv( Config.sub_csv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target context\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n",
       "2  36baf228038e314b      lower trunnion                 lower locating     B60\n",
       "3  1f37ead645e7f0c8       cap component                  upper portion     D06\n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  score\n",
       "0  4112d61851461f60      0\n",
       "1  09e418c93a776564      0\n",
       "2  36baf228038e314b      0\n",
       "3  1f37ead645e7f0c8      0\n",
       "4  71a5b6ad068d531f      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 32\n",
      "val_size 4\n"
     ]
    }
   ],
   "source": [
    "train_examples=int(len(train_df)*0.9)\n",
    "train_data=train_df.iloc[:train_examples,1:]\n",
    "val_data=train_df.iloc[train_examples:, 1:]\n",
    "print('train_size:',train_data.shape[0])\n",
    "print('val_size',val_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, anchor,target,context,score,tokenizer,max_len):\n",
    "        \n",
    "        self.anchor=anchor\n",
    "        self.target=target\n",
    "        self.context=context\n",
    "        self.score=score\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "    def __len__(self):\n",
    "        return len(self.anchor)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        anchor=self.anchor[idx]\n",
    "        target=self.target[idx]\n",
    "        context=self.context[idx]\n",
    "        score=self.score[idx]\n",
    "        \n",
    "        encoded_data=self.tokenizer.encode_plus(context+' '+anchor,target,padding='max_length',max_length=self.max_len,truncation=True,return_attention_mask=True)\n",
    "        \n",
    "        input_ids=encoded_data[\"input_ids\"]\n",
    "        attention_mask=encoded_data[\"attention_mask\"]\n",
    "        token_type_ids=encoded_data[\"token_type_ids\"]\n",
    "        \n",
    "        return{\n",
    "            'input_ids':torch.tensor(input_ids,dtype=torch.long),\n",
    "            'attention_mask':torch.tensor(attention_mask,dtype=torch.long),\n",
    "            'token_type':torch.tensor(token_type_ids,dtype=torch.long),\n",
    "            'label':torch.tensor(score,dtype=torch.long),          \n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(BertClassifier,self).__init__()\n",
    "        self.bert=BertModel.from_pretrained(Config.model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.linear=nn.Linear(1024,5)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \n",
    "        _,pooled_output=self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n",
    "        dropout_output=self.dropout(pooled_output)\n",
    "        linear_output=self.linear(dropout_output)\n",
    "        final_layer=self.relu(linear_output)\n",
    "        return final_layer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 32\n",
      "val_size: 4\n"
     ]
    }
   ],
   "source": [
    "train_examples=int(len(train_df)*0.9)\n",
    "train=train_df.iloc[:train_examples,1:]\n",
    "val=train_df.iloc[train_examples:, 1:]\n",
    "print('train_size:',train.shape[0])\n",
    "print('val_size:',val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(Config.model,padding='max_length',pad_to_max=True,max_length=Config.max_len,truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30388/2283964712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBertClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30388/2283964712.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train, val, learning_rate, epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                 \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                                 \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 max_len=Config.max_len)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "def train(model,train,val,learning_rate=.01,epochs=200):\n",
    "    train_dataset=PatentDataset(anchor=train.target.values,\n",
    "                                target=train.target.values,\n",
    "                                context=train.context.values,\n",
    "                                score=train.score.values,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_len=Config.max_len)\n",
    "    \n",
    "    val_dataset=PatentDataset(anchor=val.target.values,\n",
    "                                target=val.target.values,\n",
    "                                context=val.context.values,\n",
    "                                score=val.score.values,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_len=Config.max_len)\n",
    "    \n",
    "    train_dataloader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "    val_dataloader=DataLoader(val_dataset,batch_size=32)\n",
    "    \n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=Adam(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model=model.cuda()\n",
    "        criterion=criterion.cuda()\n",
    "        \n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train=0\n",
    "        total_loss_train=0\n",
    "        \n",
    "        for item in tqdm(train_dataloader):\n",
    "            train_label=item['label'].to(device)\n",
    "            mask=item['attention_mask'].to(device)\n",
    "            input_id=item['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            output=model(input_id,mask)\n",
    "            batch_loss=criterion(output,train_label)\n",
    "            total_loss_train+=batch_loss.item()\n",
    "            \n",
    "            acc=(output.argmax(dim=1)==train_label).sum().item()\n",
    "            total_acc_train+=acc\n",
    "            \n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_acc_val=0\n",
    "            total_loss_val=0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for item in val_dataloader:\n",
    "                \n",
    "                val_label=item['label'].to(device)\n",
    "                mask=item['attention_mask'].to(device)\n",
    "                input_id=item['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                output=model(input_id,mask)\n",
    "                \n",
    "                batch_loss=criterion(output,val_label)\n",
    "                total_loss_train+=batch_loss.item()\n",
    "                \n",
    "                acc=(output.argmax(dim=1)==val_label).sum().item()\n",
    "                total_acc_val+=acc\n",
    "        save_path=f'bert_{epoch_num}.pt'\n",
    "        torch.save({\n",
    "            'epoch':epoch_num,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "        },save_path)\n",
    "\n",
    "\n",
    "model=BertClassifier(dropout=0.5)\n",
    "train(model,train_data,val_data,Config.lr,Config.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba9f61daeaab4ced0bbcb0f07d027b08492f5a96983a9bde7c877c694a06d99c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
